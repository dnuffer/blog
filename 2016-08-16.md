My current goal is to get a fast neural style network built and trained using TensorFlow to run on iOS.

I got this error when running my tensorflow model on iOS:

```
Invalid argument: No OpKernel was registered to support Op 'Mul' with these attrs
	 [[Node: deconv1/conv_transpose/mul_1 = Mul[T=DT_INT32](deconv1/conv_transpose/strided_slice_2, deconv1/conv_transpose/mul_1/y)]]
```

This part of the graph was doing a multiplication on the shape of a tensor.
I failed to find anything on this problem via Google, so I dug into the source and found that `cwise_op_mul.cc` defines the Mul Op for all expected types. It didn't make sense why only float was in the built library. However the code was doing macro expansion, so I figured there must be something going on with that. Digging further, I found that in cwise_ops_common.h, there is some code that causes all the REGISTER* macros to only register the ops for float and no other types when building for Android (and iOS according to the Makefile):

```c++
#if defined(__ANDROID_TYPES_SLIM__)
// Normally Android TensorFlow is built with a reduced number of types (float).
// Override on the command-line "--define ANDROID_TYPES=__ANDROID_TYPES_FULL__"
// to generate a library with full type support with a consequent increase in
// code size.
#define REGISTER2(OP, D, N, F, T0, T1) REGISTER(OP, D, N, F, T0)
```

As I don't need or want all the extra ops, and I like the idea of keeping the library smaller, I added an int32 Mul Op in `cwise_op_mul.cc`:

```c++
REGISTER(BinaryOp, CPU, "Mul", functor::mul, int32);
```

After rebuilding, the error message about the missing op is gone.

The next problem:

```
Running model failed: Invalid argument: Incompatible shapes: [1,1,1,3] vs. [32]
	 [[Node: conv1/conv/batch/mul = Mul[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/cpu:0"](conv1/conv/batch/Rsqrt, conv1/conv/scale)]]
```

This was caused by a bug in my model generation, where the batch normalization code was passed a parameter of a vector of 1s. The bug is that it was the wrong shape. It was multiplied by the input, so was redundant because it was all 1s. Instead of making it the correct size, I just removed it altogether to save some CPU cycles. I don't know why this didn't cause a problem with training or evaluating the graph on Linux, but I have to now re-train the network with the new graph.
