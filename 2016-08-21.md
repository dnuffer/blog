I got this error from my generation code:
```
E tensorflow/examples/label_image/ns_main.cc:316] Running model failed: Invalid argument: Conv2DSlowBackpropInput: Size of out_backprop doesn't match computed: actual = 64, computed = 65
 [[Node: 	conv_t1/conv_t1/conv_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](conv_t1/conv_t1/pack, conv_t1/conv_t1/weights, res5/res5/add)]]
  [[Node:Node conv_t3/conv_t3/batch/moments/sufficient_statistics/Shape/_12 = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_392_conv_t3/conv_t3/batch/moments/sufficient_statistics/Shape", tensor_type=DT_INT32, _device="/job:localhost/replica:0/task:0/cpu:0"]()]]
```

Which I eventually realized was caused by the size of the test image not matching the training image.
That was the last issue I had to solve to get generation using my net working.
I don't yet know why the conv\_transpose op remembers the size from training, as conv ops are supposed to be independent of the input size, that's something I'll figure out another day.

Another important thing I had to add to my training code in order to write out a graph that is useful for deployment:
```python
input_node_names = [model_input.name]
output_node_names = ['output']
graph_def = sess.graph_def
graph_def = graph_util.convert_variables_to_constants(sess, graph_def, output_node_names)
graph_def = strip_unused_lib.strip_unused(graph_def, input_node_names, output_node_names, tf.float32.as_datatype_enum)
graph_def = graph_util.remove_training_nodes(graph_def)

tf.train.write_graph(graph_def, FLAGS.MODEL_PATH, 'input_graph_optimized.pb', as_text=False)
tf.train.write_graph(graph_def, FLAGS.MODEL_PATH, 'input_graph_optimized.pbtxt', as_text=True)
```

This is what the generated image of looks like:
[2016-08-21/ns_main_out.png]

I found that vim 7.3 supports markdown syntax, but only enabled it for .markdown extensions. The default for .md is modula. I don't ever think I'll write modula code so I added 
```
au BufNewFile,BufFilePre,BufRead *.md set filetype=markdown
```
to my .vimrc
Apparently a newer version of vim does this by default. https://stackoverflow.com/questions/10964681/enabling-markdown-highlighting-in-vim

The final thing I needed to do to get the network to run on iOS is to remove the FIFOQueue and QueueDequeMany nodes from the graph. For some reason strip\_unused() wasn't removing them, and so I created my own version of remove\_training\_nodes() which does remove them. This was the final hurdle. The net runs and generates a style-transfer image in 2.2 sec on my iPhone 5s.
